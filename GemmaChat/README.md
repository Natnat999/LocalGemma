# GemmaChat - Assistant IA Local pour Android

## Description

GemmaChat est une application Android native qui intÃ¨gre le modÃ¨le Gemma 1B pour fournir un assistant IA conversationnel fonctionnant entiÃ¨rement hors ligne sur l'appareil. L'application offre une interface moderne basÃ©e sur Material Design 3 avec support des thÃ¨mes clairs et sombres.

## FonctionnalitÃ©s principales

- ğŸ¤– **IA locale** : ExÃ©cution du modÃ¨le Gemma 1B directement sur l'appareil via llama.cpp
- ğŸ’¬ **Interface de chat temps rÃ©el** : Conversation fluide avec l'assistant IA
- ğŸ¨ **Design Material 3** : Interface moderne avec support des thÃ¨mes dynamiques (Android 12+)
- ğŸŒ **Multilingue** : Support du franÃ§ais et de l'anglais
- ğŸ“± **CompatibilitÃ© Ã©tendue** : Fonctionne sur Android 8.0 (API 26) et versions ultÃ©rieures
- ğŸ”’ **ConfidentialitÃ©** : Aucune donnÃ©e n'est transmise en ligne
- ğŸ’¾ **Historique local** : Sauvegarde des conversations avec Room
- ğŸ”” **Notifications** : Alertes locales pour les rÃ©ponses en arriÃ¨re-plan

## Architecture technique

### Technologies utilisÃ©es

- **Langage** : Kotlin
- **UI** : Jetpack Compose avec Material 3
- **Architecture** : MVVM avec ViewModel et StateFlow
- **Base de donnÃ©es** : Room pour la persistance locale
- **PrÃ©fÃ©rences** : DataStore
- **IA** : llama.cpp via JNI pour l'exÃ©cution du modÃ¨le
- **Injection de dÃ©pendances** : Singleton pattern manuel

### Structure du projet

```
GemmaChat/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/main/
â”‚   â”‚   â”œâ”€â”€ java/com/gemmachat/
â”‚   â”‚   â”‚   â”œâ”€â”€ data/              # ModÃ¨les de donnÃ©es et repository
â”‚   â”‚   â”‚   â”œâ”€â”€ llm/               # Interface JNI pour llama.cpp
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/                # Composants UI et Ã©crans
â”‚   â”‚   â”‚   â”œâ”€â”€ utils/             # Utilitaires
â”‚   â”‚   â”‚   â”œâ”€â”€ viewmodels/        # ViewModels
â”‚   â”‚   â”‚   â””â”€â”€ MainActivity.kt
â”‚   â”‚   â”œâ”€â”€ cpp/                   # Code natif C++ pour llama.cpp
â”‚   â”‚   â””â”€â”€ res/                   # Ressources (layouts, strings, etc.)
â”‚   â””â”€â”€ build.gradle.kts
â””â”€â”€ README.md
```

## Installation et compilation

### PrÃ©requis

- Android Studio Arctic Fox ou plus rÃ©cent
- Android SDK 34
- NDK 25.x ou plus rÃ©cent
- CMake 3.22.1

### Ã‰tapes de compilation

1. Cloner le dÃ©pÃ´t llama.cpp dans `app/src/main/cpp/llama.cpp`
2. Placer le modÃ¨le Gemma 1B au format GGUF dans `app/src/main/assets/models/`
3. Ouvrir le projet dans Android Studio
4. Synchroniser le projet avec Gradle
5. Compiler et exÃ©cuter sur un appareil ou Ã©mulateur

### Configuration du modÃ¨le

Le modÃ¨le Gemma 1B doit Ãªtre converti au format GGUF. Utilisez les outils de llama.cpp pour la conversion :

```bash
python convert.py gemma-1b-it --outtype q4_k_m --outfile gemma-1b-it-q4_k_m.gguf
```

## Optimisations

- **Quantification** : Le modÃ¨le utilise la quantification Q4_K_M pour rÃ©duire la taille et amÃ©liorer les performances
- **Threading** : Utilisation de 4 threads pour l'infÃ©rence
- **Contexte** : LimitÃ© Ã  2048 tokens pour optimiser la mÃ©moire
- **Batch size** : 512 pour un Ã©quilibre entre vitesse et utilisation mÃ©moire

## Limitations connues

- Le modÃ¨le nÃ©cessite environ 1-2 GB de RAM disponible
- Les performances peuvent varier selon l'appareil
- La premiÃ¨re gÃ©nÃ©ration peut Ãªtre plus lente (chargement du modÃ¨le)

## Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.

## Contributions

Les contributions sont les bienvenues ! Veuillez crÃ©er une issue pour discuter des changements majeurs avant de soumettre une pull request.